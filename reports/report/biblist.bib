@book{SQL,
 author = {Widenius, Michael and Axmark, Davis},
 editor = {DuBois, Paul},
 title = {Mysql Reference Manual},
 year = {2002},
 isbn = {0596002653},
 edition = {1st},
 publisher = {O'Reilly \& Associates, Inc.},
 address = {Sebastopol, CA, USA},
} 

@article{VAETut,
       author = {{Doersch}, Carl},
        title = "{Tutorial on Variational Autoencoders}",
      journal = {arXiv e-prints},
     keywords = {Statistics - Machine Learning, Computer Science - Machine Learning},
         year = "2016",
        month = "Jun",
          eid = {arXiv:1606.05908},
        pages = {arXiv:1606.05908},
archivePrefix = {arXiv},
       eprint = {1606.05908},
 primaryClass = {stat.ML},
       adsurl = {https://ui.adsabs.harvard.edu/abs/2016arXiv160605908D},
      adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}

@article{fisher_1936, title={The Use Of Multiple Measurements In Taxonomic Problems}, volume={7}, DOI={10.1111/j.1469-1809.1936.tb02137.x}, number={2}, journal={Annals of Eugenics}, author={Fisher, R. A.}, year={1936}, pages={179â€“188}}


@article{aeberhard_coomans_de_vel_1992,
  title={Comparative analysis of statistical pattern recognition methods in high dimensional settings},
  author={Aeberhard, Stefan and Coomans, Danny and De Vel, Olivier},
  journal={Pattern Recognition},
  volume={27},
  number={8},
  pages={1065--1077},
  year={1994},
  publisher={Elsevier}
}

@article{street_wolberg_mangasarian_1993, title={}, DOI={10.1117/12.148698}, journal={Biomedical Image Processing and Biomedical Visualization}, author={Street, W. N. and Wolberg, W. H. and Mangasarian, O. L.}, year={1993}}

@misc{pascal-chsc-2011, author = "Bentley, P. and Nordehn, G. and Coimbra, M. and Mannor, S.", title = "The {PASCAL} {C}lassifying {H}eart {S}ounds {C}hallenge 2011 {(CHSC2011)} {R}esults", howpublished = "http://www.peterjbentley.com/heartchallenge/index.html"}



@ARTICLE{vaeBayes,
       author = {{Kingma}, Diederik P and {Welling}, Max},
        title = "{Auto-Encoding Variational Bayes}",
      journal = {arXiv e-prints},
     keywords = {Statistics - Machine Learning, Computer Science - Machine Learning},
         year = "2013",
        month = "Dec",
          eid = {arXiv:1312.6114},
        pages = {arXiv:1312.6114},
archivePrefix = {arXiv},
       eprint = {1312.6114},
 primaryClass = {stat.ML},
       adsurl = {https://ui.adsabs.harvard.edu/abs/2013arXiv1312.6114K},
      adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}


@article{zhao2017infovae,
  title={Infovae: Information maximizing variational autoencoders},
  author={Zhao, Shengjia and Song, Jiaming and Ermon, Stefano},
  journal={arXiv preprint arXiv:1706.02262},
  year={2017}
}

@article{tolstikhin2017wasserstein,
  title={Wasserstein auto-encoders},
  author={Tolstikhin, Ilya and Bousquet, Olivier and Gelly, Sylvain and Schoelkopf, Bernhard},
  journal={arXiv preprint arXiv:1711.01558},
  year={2017}
}

@article{Bengio2013,
abstract = {The success of machine learning algorithms generally depends on data representation, and we hypothesize that this is because different representations can entangle and hide more or less the different explanatory factors of variation behind the data. Although specific domain knowledge can be used to help design representations, learning with generic priors can also be used, and the quest for AI is motivating the design of more powerful representation-learning algorithms implementing such priors. This paper reviews recent work in the area of unsupervised feature learning and deep learning, covering advances in probabilistic models, autoencoders, manifold learning, and deep networks. This motivates longer term unanswered questions about the appropriate objectives for learning good representations, for computing representations (i.e., inference), and the geometrical connections between representation learning, density estimation, and manifold learning.},
archivePrefix = {arXiv},
arxivId = {arXiv:1206.5538v3},
author = {Bengio, Yoshua and Courville, Aaron and Vincent, Pascal},
doi = {10.1109/TPAMI.2013.50},
eprint = {arXiv:1206.5538v3},
file = {:home/marcusskky/Downloads/1206.5538.pdf:pdf},
issn = {01628828},
journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
keywords = {Boltzmann machine,Deep learning,autoencoder,feature learning,neural nets,representation learning,unsupervised learning},
number = {8},
pages = {1798--1828},
title = {{Representation learning: A review and new perspectives}},
volume = {35},
year = {2013}
}


@article{Bengio2007,
author = {Bengio, Yoshua and Lamblin, Pascal and Popovici, Dan and Larochelle, Hugo},
doi = {10.1016/S0022-5193(05)80076-1},
file = {:home/marcusskky/Downloads/3048-greedy-layer-wise-training-of-deep-networks.pdf:pdf},
issn = {10958541},
journal = {In Advances in neural information processing system},
title = {{Greedy Layer-Wise Training of Deep Networks Yoshua}},
year = {2007}
}


@article{An2015,
abstract = {We propose an anomaly detection method using the reconstruction probability from the variational autoencoder. The reconstruction probability is a probabilistic measure that takes into account the variability of the distribution of variables. The reconstruction probability has a theoretical background making it a more principled and objective anomaly score than the reconstruction error, which is used by autoencoder and principal components based anomaly detection methods. Experimental results show that the proposed method outper-forms autoencoder based and principal components based methods. Utilizing the generative characteristics of the variational autoencoder enables deriving the reconstruction of the data to analyze the underlying cause of the anomaly.},
author = {An, Jinwon and Cho, Sungzoon},
file = {:Users/singo/Desktop/anomoly.pdf:pdf},
title = {{SNU Data Mining Center 2015-2 Special Lecture on IE Variational Autoencoder based Anomaly Detection using Reconstruction Probability}},
year = {2015}
}

@article{Kameoka2019,
abstract = {This paper proposes a non-parallel many-to-many voice conversion (VC) method using a variant of the conditional variational autoencoder (VAE) called an auxiliary classifier VAE (ACVAE). The proposed method has three key features. First, it adopts fully convolutional architectures to construct the encoder and decoder networks so that the networks can learn conversion rules that capture time dependencies in the acoustic feature sequences of source and target speech. Second, it uses an information-theoretic regularization for the model training to ensure that the information in the attribute class label will not be lost in the conversion process. With regular CVAEs, the encoder and decoder are free to ignore the attribute class label input. This can be problematic since in such a situation, the attribute class label will have little effect on controlling the voice characteristics of input speech at test time. Such situations can be avoided by introducing an auxiliary classifier and training the encoder and decoder so that the attribute classes of the decoder outputs are correctly predicted by the classifier. Third, it avoids producing buzzy-sounding speech at test time by simply transplanting the spectral details of the input speech into its converted version. Subjective evaluation experiments revealed that this simple method worked reasonably well in a non-parallel many-to-many speaker identity conversion task.},
archivePrefix = {arXiv},
arxivId = {arXiv:1808.05092v2},
author = {Kameoka, Hirokazu and Kaneko, Takuhiro and Tanaka, Kou and Hojo, Nobukatsu},
doi = {10.1109/TASLP.2019.2917232},
eprint = {arXiv:1808.05092v2},
file = {:home/marcusskky/Downloads/1808.05092.pdf:pdf},
issn = {23299290},
journal = {IEEE/ACM Transactions on Audio Speech and Language Processing},
keywords = {Voice conversion (VC),auxiliary classifier VAE (ACVAE),fully convolutional network,non-parallel VC,variational autoencoder (VAE)},
number = {9},
pages = {1432--1443},
title = {{ACVAE-VC: Non-Parallel Voice Conversion with Auxiliary Classifier Variational Autoencoder}},
volume = {27},
year = {2019}
}


@article{Walker2016,
abstract = {In a given scene, humans can often easily predict a set of immediate future events that might happen. However, generalized pixel-level anticipation in computer vision systems is difficult because machine learning struggles with the ambiguity inherent in predicting the future. In this paper, we focus on predicting the dense trajectory of pixels in a scene, specifically what will move in the scene, where it will travel, and how it will deform over the course of one second. We propose a conditional variational autoencoder as a solution to this problem. In this framework, direct inference from the image shapes the distribution of possible trajectories, while latent variables encode any necessary information that is not available in the image. We show that our method is able to successfully predict events in a wide variety of scenes and can produce multiple different predictions when the future is ambiguous. Our algorithm is trained on thousands of diverse, realistic videos and requires absolutely no human labeling. In addition to non-semantic action prediction, we find that our method learns a representation that is applicable to semantic vision tasks.},
archivePrefix = {arXiv},
arxivId = {arXiv:1606.07873v1},
author = {Walker, Jacob and Doersch, Carl and Gupta, Abhinav and Hebert, Martial},
doi = {10.1007/978-3-319-46478-7_51},
eprint = {arXiv:1606.07873v1},
file = {:Users/singo/Desktop/Mend/1606.07873.pdf:pdf},
isbn = {9783319464770},
issn = {16113349},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
keywords = {Action forecasting,Generative models,Scene understanding,Variational autoencoders},
pages = {835--851},
title = {{An uncertain future: Forecasting from static images using variational autoencoders}},
volume = {9911 LNCS},
year = {2016}
}

@article{Goodfellow2014,
abstract = {We propose a new framework for estimating generative models via an adversar-ial process, in which we simultaneously train two models: a generative model G that captures the data distribution, and a discriminative model D that estimates the probability that a sample came from the training data rather than G. The training procedure for G is to maximize the probability of D making a mistake. This framework corresponds to a minimax two-player game. In the space of arbitrary functions G and D, a unique solution exists, with G recovering the training data distribution and D equal to 1 2 everywhere. In the case where G and D are defined by multilayer perceptrons, the entire system can be trained with backpropagation. There is no need for any Markov chains or unrolled approximate inference networks during either training or generation of samples. Experiments demonstrate the potential of the framework through qualitative and quantitative evaluation of the generated samples.},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Goodfellow, Ian and Pouget-Abadie, Jean and Mirza, Mehdi and Xu, Bing and Warde-Farley, David and Ozair, Sherjil and Courville, Aaron and Bengio, Yoshua},
doi = {10.1016/B978-0-408-00109-0.50001-8},
eprint = {arXiv:1011.1669v3},
file = {:Users/singo/Desktop/Mend/5423-generative-adversarial-nets.pdf:pdf},
isbn = {9780300023077},
issn = {03787753},
pages = {iii},
pmid = {15645445},
title = {{Generative Adversarial Nets}},
url = {https://papers.nips.cc/paper/5423-generative-adversarial-nets{\%}0Ahttp://doi.wiley.com/10.1002/9781118472507.fmatter{\%}0Ahttp://linkinghub.elsevier.com/retrieve/pii/B9780408001090500018},
year = {2014}
}
